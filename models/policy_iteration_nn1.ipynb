{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "import interface as bb\n",
    "cimport interface as bb\n",
    "\n",
    "import cPickle\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "from libc.math cimport fabs, tanh\n",
    "from scipy.linalg.cython_blas cimport sgemm\n",
    "\n",
    "cimport cython\n",
    "\n",
    "cdef:\n",
    "    int NUM_HIDDEN = 100\n",
    "    float b1[100]\n",
    "    float b2[4]\n",
    "    float min_state[36]\n",
    "    float dif_state[36]\n",
    "\n",
    "cdef float alpha = 1.0, beta = 0.0\n",
    "cdef float[::1,:] s, h, y, w1, w2\n",
    "\n",
    "s = np.empty((1,36), np.float32, order=\"F\")\n",
    "w1 = np.empty((36,NUM_HIDDEN), np.float32, order=\"F\")\n",
    "h = np.empty((1,NUM_HIDDEN), np.float32, order=\"F\")\n",
    "w2 = np.empty((NUM_HIDDEN,4), np.float32, order=\"F\")\n",
    "y = np.empty((1,4), np.float32, order=\"F\")\n",
    "\n",
    "cdef int NUM_CACHE = 51\n",
    "cdef int cache_i = 0, cache_n = 0\n",
    "cdef float[::1,:] cache_s, cache_y\n",
    "\n",
    "cache_s = np.empty((NUM_CACHE,36), np.float32, order=\"F\")\n",
    "cache_y = np.empty((NUM_CACHE,4), np.float32, order=\"F\")\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef void fast_target(float *state, int use_cache = 0):\n",
    "    global cache_i, cache_n\n",
    "    cdef int i, c, m, n, k, lda, ldb, ldc\n",
    "    \n",
    "    if use_cache == 1:\n",
    "        c = 0\n",
    "        while c < cache_n:\n",
    "            i = 0\n",
    "            while i < 36:\n",
    "                if cache_s[c,i] != state[i]:\n",
    "                    break\n",
    "                i += 1\n",
    "            if i == 36:\n",
    "                for i in xrange(4):\n",
    "                    y[0,i] = cache_y[c,i]\n",
    "                return\n",
    "            c += 1\n",
    "        cache_i += 1\n",
    "        if cache_i == NUM_CACHE:\n",
    "            cache_i = 0\n",
    "        if cache_n < NUM_CACHE:\n",
    "            cache_n += 1\n",
    "        for i in xrange(36):\n",
    "            cache_s[cache_i,i] = state[i]\n",
    "            s[0,i] = (state[i] - min_state[i]) / dif_state[i]\n",
    "    else:\n",
    "        for i in xrange(36):\n",
    "            s[0,i] = (state[i] - min_state[i]) / dif_state[i]\n",
    "    \n",
    "    lda = 1\n",
    "    ldb = 36\n",
    "    ldc = 1\n",
    "    m = 1\n",
    "    n = NUM_HIDDEN\n",
    "    k = 36\n",
    "    sgemm(\"N\", \"N\", &m, &n, &k, &alpha, &s[0,0], &lda, &w1[0,0], &ldb, &beta, &h[0,0], &ldc)\n",
    "    \n",
    "    for i in xrange(NUM_HIDDEN):\n",
    "        h[0,i] = tanh(h[0,i] + b1[i])\n",
    "    \n",
    "    lda = 1\n",
    "    ldb = NUM_HIDDEN\n",
    "    ldc = 1\n",
    "    m = 1\n",
    "    n = 4\n",
    "    k = NUM_HIDDEN\n",
    "    sgemm(\"N\", \"N\", &m, &n, &k, &alpha, &h[0,0], &lda, &w2[0,0], &ldb, &beta, &y[0,0], &ldc)\n",
    "    \n",
    "    if use_cache == 1:\n",
    "        for i in xrange(4):\n",
    "            cache_y[cache_i,i] = y[0,i]\n",
    "    \n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef int fast_action(float *state, int use_cache = 0):\n",
    "    cdef int i, best_act = -1\n",
    "    cdef float x, best_val = -1e9\n",
    "    fast_target(state, use_cache)\n",
    "    for i in xrange(4):\n",
    "        x = y[0,i] + b2[i]\n",
    "        if x > best_val:\n",
    "            best_val = x\n",
    "            best_act = i\n",
    "    return best_act\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef float fast_value(float *state):\n",
    "    cdef int i\n",
    "    cdef float x, best_val = -1e9\n",
    "    fast_target(state, 1)\n",
    "    for i in xrange(4):\n",
    "        x = y[0,i] + b2[i]\n",
    "        if x > best_val:\n",
    "            best_val = x\n",
    "    return best_val\n",
    "\n",
    "\n",
    "def dump_embedding():\n",
    "    cdef int i\n",
    "    global min_state, dif_state\n",
    "    state_min = None\n",
    "    state_dif = None\n",
    "    with open('state36.pkl', 'r') as file:\n",
    "        embedding = cPickle.load(file)\n",
    "        state_min = embedding['state_min']\n",
    "        state_dif = embedding['state_dif']\n",
    "        for i in xrange(36):\n",
    "            min_state[i] = state_min[i]\n",
    "            dif_state[i] = state_dif[i]\n",
    "    return state_min, state_dif\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def dump_weights(weights):\n",
    "    cdef int i, j\n",
    "    for i in xrange(NUM_HIDDEN):\n",
    "        for j in xrange(36):\n",
    "            w1[j,i] = weights[0][j,i]\n",
    "        b1[i] = weights[1][i]\n",
    "    for i in xrange(4):\n",
    "        for j in xrange(NUM_HIDDEN):\n",
    "            w2[j,i] = weights[2][j,i]\n",
    "        b2[i] = weights[3][i]\n",
    "\n",
    "\n",
    "def prepare_bbox(level='train', verbose=0):\n",
    "    if bb.is_level_loaded():\n",
    "        bb.reset_level()\n",
    "    bb.load_level('../levels/'+level+'_level.data', verbose)\n",
    "\n",
    "\n",
    "cdef float _rewards[4]\n",
    "cdef float _mask[4]\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef crollout(int epoch=0, float curriculum=0.7):\n",
    "    cdef:\n",
    "        int i, a, action, has_next, checkpoint_id, has_change\n",
    "        float r, prev_score, init_state35, next_state35, next_state35_abs, prev_state35_abs\n",
    "        float *state\n",
    "    \n",
    "    init_state35 = bb.c_get_state()[35]\n",
    "    checkpoint_id = bb.create_checkpoint()\n",
    "   \n",
    "    for a in xrange(4):\n",
    "        \n",
    "        _rewards[a] = 0\n",
    "        _mask[a] = 0\n",
    "        \n",
    "        prev_score = bb.c_get_score()\n",
    "        has_next = bb.c_do_action(a)\n",
    "        state = bb.c_get_state()\n",
    "        next_state35 = state[35]  \n",
    "        \n",
    "        if init_state35 != next_state35 or np.random.rand() < curriculum:\n",
    "                        \n",
    "            r = bb.c_get_score() - prev_score\n",
    "            prev_score = bb.c_get_score()\n",
    "            \n",
    "            if has_next == 1:\n",
    "                for i in xrange(50):\n",
    "                    if epoch > 0:\n",
    "                        action = fast_action(state, 1)\n",
    "                    else:\n",
    "                        action = 3\n",
    "\n",
    "                    has_next = bb.c_do_action(action)\n",
    "                    r += bb.c_get_score() - prev_score\n",
    "                    state = bb.c_get_state()\n",
    "                    prev_score = bb.c_get_score()\n",
    "                    if has_next == 0:\n",
    "                        break\n",
    "                \n",
    "                if has_next == 1 and epoch > 0:\n",
    "                    r += fast_value(state)\n",
    "\n",
    "            _rewards[a] = r\n",
    "            _mask[a] = 1\n",
    "        \n",
    "        bb.load_from_checkpoint(checkpoint_id)\n",
    "    bb.clear_all_checkpoints()\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def rollout(epoch=0, curriculum=0.7):\n",
    "    cdef int i\n",
    "    crollout(epoch, curriculum)\n",
    "    rewards = np.empty(4, dtype=np.float32)\n",
    "    mask = np.empty(4, dtype=np.float32)\n",
    "    for i in xrange(4):\n",
    "        rewards[i] = _rewards[i]\n",
    "        mask[i] = _mask[i]\n",
    "    if (rewards == 0).all():\n",
    "        return None, None\n",
    "    return rewards, mask\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "def build_model():\n",
    "    \n",
    "    l_input = lasagne.layers.InputLayer((None, 36))\n",
    "    l_input = lasagne.layers.GaussianNoiseLayer(l_input, sigma=0.01)\n",
    "    l_hidden = lasagne.layers.DenseLayer(\n",
    "        l_input,\n",
    "        num_units=NUM_HIDDEN,\n",
    "        W=lasagne.init.Normal(),\n",
    "        nonlinearity=lasagne.nonlinearities.tanh\n",
    "    )\n",
    "    l_out = lasagne.layers.GaussianNoiseLayer(l_hidden, sigma=0.01)\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_out,\n",
    "        num_units=4,\n",
    "        W=lasagne.init.Normal(),\n",
    "        nonlinearity=None\n",
    "    )\n",
    "\n",
    "    state = T.matrix('state')\n",
    "    target = T.matrix('target')\n",
    "    mask = T.matrix('mask')\n",
    "\n",
    "    prediction = lasagne.layers.get_output(l_out, state)\n",
    "    loss = T.mean(mask * (prediction - target)**2)\n",
    "    params = lasagne.layers.helper.get_all_params(l_out)\n",
    "    grads = T.grad(loss, params)\n",
    "    updates = lasagne.updates.adam(grads, params, .0001)\n",
    "    train = theano.function([state, target, mask], loss, updates=updates)\n",
    "    grads = [T.sqrt(T.sum(g**2)) for g in grads]\n",
    "    debug = theano.function([state, target, mask], grads)\n",
    "    \n",
    "    return l_out, train, debug\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def policy_iteration(n_epochs=20):\n",
    "    cdef int epoch, action\n",
    "    \n",
    "    best_score = 3000\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    \n",
    "    curriculum = 0.3\n",
    "    curriculum_max = 1\n",
    "    curriculum_inc = (curriculum_max - curriculum) / 10.0\n",
    "    \n",
    "    state_min, state_dif = dump_embedding()\n",
    "    \n",
    "    model, train, debug = build_model()\n",
    "    weights_out = []\n",
    "    \n",
    "    def train_epoch(X, Y, M):\n",
    "        cdef float loss = 0\n",
    "        cdef int i = 0, e = min(5, 2 + epoch)\n",
    "        for _ in xrange(e):\n",
    "            N = X.shape[0]\n",
    "            I = np.random.permutation(N)\n",
    "            X = X[I]\n",
    "            Y = Y[I]\n",
    "            M = M[I]\n",
    "            N = int(N / BATCH_SIZE)\n",
    "            for b in xrange(N):\n",
    "                Xb = X[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "                Yb = Y[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "                Mb = M[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "                loss += train(Xb, Yb, Mb)\n",
    "                i += 1\n",
    "                if np.isnan(loss):\n",
    "                    raise TypeError(\"Loss function return NaN!\")\n",
    "\n",
    "        W = lasagne.layers.get_all_param_values(model)\n",
    "        \n",
    "        G = debug(Xb, Yb, Mb)\n",
    "        for w, g in zip(W, G):\n",
    "            print \"{:10s} \\t {:8.5f} \\t {:8.5f}\".format(w.shape, np.sqrt((w**2).sum()), float(g))\n",
    "\n",
    "        print \"Updates {}, Loss = {:.4f}\".format(i, loss / i)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        prepare_bbox('train')\n",
    "        while True:\n",
    "            \n",
    "            rewards, mask = rollout(epoch, curriculum)\n",
    "            if rewards is not None:\n",
    "                state = (bb.get_state() - state_min) / state_dif\n",
    "                X.append(state)\n",
    "                Y.append(rewards)\n",
    "                M.append(mask)\n",
    "            \n",
    "            if epoch > 0:\n",
    "                action = fast_action(bb.c_get_state(), 1)\n",
    "            else:\n",
    "                action = np.random.randint(4)\n",
    "\n",
    "            if bb.c_do_action(action) == 0:\n",
    "                train_score = bb.finish(verbose=0)\n",
    "                break\n",
    "        \n",
    "            \n",
    "        Xa = np.array(X).astype(np.float32)\n",
    "        Ya = np.array(Y).astype(np.float32)\n",
    "        Ma = np.array(M).astype(np.float32)\n",
    "\n",
    "        del X[:]\n",
    "        del Y[:]\n",
    "        del M[:]\n",
    "        \n",
    "        weights = train_epoch(Xa, Ya, Ma)\n",
    "        weights_out.append(weights)\n",
    "        \n",
    "        print 'Epoch: {}, sample prob: {}, time: {}'.format(epoch, curriculum, int(time.time() - start))\n",
    "        test_score, _ = test(weights)\n",
    "        print\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        dump_weights(weights)\n",
    "        \n",
    "        if test_score > best_score:\n",
    "            with open('best_weights' + str(NUM_HIDDEN) + '.pkl', 'w') as f:\n",
    "                cPickle.dump(weights, f)\n",
    "            best_score = test_score\n",
    "            \n",
    "        curriculum = min(curriculum_max, curriculum + curriculum_inc)\n",
    "    \n",
    "    return weights_out\n",
    "\n",
    "def test(weights):\n",
    "    cdef:\n",
    "        int action, has_next\n",
    "    \n",
    "    dump_weights(weights)\n",
    "    results = []\n",
    "    for lvl in  ('train', 'test'):\n",
    "        prepare_bbox(lvl)\n",
    "        has_next = 1\n",
    "        while has_next:\n",
    "            action = fast_action(bb.c_get_state(), 0)\n",
    "            has_next = bb.c_do_action(action)\n",
    "        results.append(bb.finish(verbose=0))\n",
    "    print 'average  {:.2f}, test {:.2f}, train {:.2f}'.format(0.5*sum(results), results[1], results[0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 100)  \t  1.56723 \t  0.57385\n",
      "(100,)     \t  0.09669 \t  0.10844\n",
      "(100, 4)   \t  0.91437 \t  0.70127\n",
      "(4,)       \t  0.03150 \t  0.47361\n",
      "Updates 28504, Loss = 36.9030\n",
      "Epoch: 0, c: 0.3, time: 40\n",
      "average  -1843.96, test -2043.42, train -1644.50\n",
      "\n",
      "(36, 100)  \t  2.71635 \t  0.51340\n",
      "(100,)     \t  0.05232 \t  0.04172\n",
      "(100, 4)   \t  2.18728 \t  0.10587\n",
      "(4,)       \t  0.03125 \t  0.17020\n",
      "Updates 48609, Loss = 5.9740\n",
      "Epoch: 1, c: 0.37, time: 287\n",
      "average  -3265.62, test -3175.42, train -3355.82\n",
      "\n",
      "(36, 100)  \t  3.06918 \t  0.98991\n",
      "(100,)     \t  0.14694 \t  0.24327\n",
      "(100, 4)   \t  2.03435 \t  0.12500\n",
      "(4,)       \t  0.07346 \t  0.12720\n",
      "Updates 68964, Loss = 3.3210\n",
      "Epoch: 2, c: 0.44, time: 339\n",
      "average  -2262.89, test -2365.25, train -2160.53\n",
      "\n",
      "(36, 100)  \t  3.48308 \t  0.95613\n",
      "(100,)     \t  0.17000 \t  0.28851\n",
      "(100, 4)   \t  1.55946 \t  0.19250\n",
      "(4,)       \t  0.10041 \t  0.22603\n",
      "Updates 89785, Loss = 3.3931\n",
      "Epoch: 3, c: 0.51, time: 342\n",
      "average  -3449.04, test -3244.55, train -3653.53\n",
      "\n",
      "(36, 100)  \t  3.94572 \t  0.75316\n",
      "(100,)     \t  0.20001 \t  0.19440\n",
      "(100, 4)   \t  1.73313 \t  0.23201\n",
      "(4,)       \t  0.11493 \t  0.15461\n",
      "Updates 92120, Loss = 3.0131\n",
      "Epoch: 4, c: 0.58, time: 418\n",
      "average  -935.40, test -1139.89, train -730.91\n",
      "\n",
      "(36, 100)  \t  4.33426 \t  0.59896\n",
      "(100,)     \t  0.18947 \t  0.18797\n",
      "(100, 4)   \t  1.20147 \t  0.22942\n",
      "(4,)       \t  0.11222 \t  0.21300\n",
      "Updates 93550, Loss = 2.3912\n",
      "Epoch: 5, c: 0.65, time: 449\n",
      "average  -298.70, test -267.40, train -330.00\n",
      "\n",
      "(36, 100)  \t  4.80334 \t  0.95915\n",
      "(100,)     \t  0.32257 \t  0.30053\n",
      "(100, 4)   \t  2.12457 \t  0.25917\n",
      "(4,)       \t  0.13881 \t  0.16049\n",
      "Updates 94340, Loss = 3.2344\n",
      "Epoch: 6, c: 0.72, time: 360\n",
      "average  901.45, test 951.60, train 851.30\n",
      "\n",
      "(36, 100)  \t  5.39309 \t  0.79594\n",
      "(100,)     \t  0.39680 \t  0.21706\n",
      "(100, 4)   \t  1.53649 \t  0.41332\n",
      "(4,)       \t  0.14840 \t  0.17260\n",
      "Updates 94710, Loss = 1.5626\n",
      "Epoch: 7, c: 0.79, time: 467\n",
      "average  2453.90, test 2640.01, train 2267.78\n",
      "\n",
      "(36, 100)  \t  6.40949 \t  0.49748\n",
      "(100,)     \t  0.41348 \t  0.14463\n",
      "(100, 4)   \t  1.99263 \t  0.30552\n",
      "(4,)       \t  0.11335 \t  0.09240\n",
      "Updates 94845, Loss = 2.2519\n",
      "Epoch: 8, c: 0.86, time: 448\n",
      "average  2535.25, test 2616.89, train 2453.62\n",
      "\n",
      "(36, 100)  \t  7.67342 \t  0.74770\n",
      "(100,)     \t  0.46717 \t  0.17420\n",
      "(100, 4)   \t  2.61033 \t  0.37206\n",
      "(4,)       \t  0.09135 \t  0.07428\n",
      "Updates 94880, Loss = 2.8980\n",
      "Epoch: 9, c: 0.93, time: 549\n",
      "average  2961.35, test 3176.30, train 2746.40\n",
      "\n",
      "(36, 100)  \t  8.84265 \t  1.81234\n",
      "(100,)     \t  0.51455 \t  0.41282\n",
      "(100, 4)   \t  3.39257 \t  0.86817\n",
      "(4,)       \t  0.08543 \t  0.21449\n",
      "Updates 94880, Loss = 3.6387\n",
      "Epoch: 10, c: 1.0, time: 457\n",
      "average  3156.87, test 3494.64, train 2819.10\n",
      "\n",
      "(36, 100)  \t  9.98324 \t  1.13749\n",
      "(100,)     \t  0.56699 \t  0.31737\n",
      "(100, 4)   \t  4.23057 \t  0.54621\n",
      "(4,)       \t  0.08024 \t  0.13225\n",
      "Updates 94880, Loss = 4.5968\n",
      "Epoch: 11, c: 1, time: 557\n",
      "average  2960.39, test 3341.17, train 2579.61\n",
      "\n",
      "(36, 100)  \t 11.04049 \t  1.89470\n",
      "(100,)     \t  0.61162 \t  0.57359\n",
      "(100, 4)   \t  5.03236 \t  0.63890\n",
      "(4,)       \t  0.08257 \t  0.16771\n",
      "Updates 94880, Loss = 6.6967\n",
      "Epoch: 12, c: 1, time: 554\n",
      "average  2739.73, test 3114.00, train 2365.47\n",
      "\n",
      "(36, 100)  \t 11.85186 \t  2.67828\n",
      "(100,)     \t  0.64723 \t  0.78919\n",
      "(100, 4)   \t  5.67695 \t  1.05228\n",
      "(4,)       \t  0.09672 \t  0.23217\n",
      "Updates 94880, Loss = 9.1683\n",
      "Epoch: 13, c: 1, time: 498\n",
      "average  2930.93, test 3125.45, train 2736.41\n",
      "\n",
      "(36, 100)  \t 12.55702 \t  6.81006\n",
      "(100,)     \t  0.69191 \t  1.93206\n",
      "(100, 4)   \t  6.27118 \t  2.09912\n",
      "(4,)       \t  0.11384 \t  0.53264\n",
      "Updates 94880, Loss = 12.2966\n",
      "Epoch: 14, c: 1, time: 569\n",
      "average  2894.32, test 3237.35, train 2551.28\n",
      "\n",
      "(36, 100)  \t 13.21878 \t  7.40876\n",
      "(100,)     \t  0.76379 \t  2.11811\n",
      "(100, 4)   \t  6.84745 \t  2.49628\n",
      "(4,)       \t  0.12601 \t  0.59937\n",
      "Updates 94880, Loss = 15.1282\n",
      "Epoch: 15, c: 1, time: 489\n",
      "average  2820.39, test 3105.28, train 2535.51\n",
      "\n",
      "(36, 100)  \t 13.81822 \t  7.94165\n",
      "(100,)     \t  0.83892 \t  2.21404\n",
      "(100, 4)   \t  7.36476 \t  3.12331\n",
      "(4,)       \t  0.13998 \t  0.64075\n",
      "Updates 94880, Loss = 16.7346\n",
      "Epoch: 16, c: 1, time: 574\n",
      "average  2912.87, test 3218.43, train 2607.31\n",
      "\n",
      "(36, 100)  \t 14.38892 \t  9.18772\n",
      "(100,)     \t  0.92140 \t  2.69630\n",
      "(100, 4)   \t  7.85557 \t  2.95132\n",
      "(4,)       \t  0.15042 \t  0.65365\n",
      "Updates 94880, Loss = 15.5377\n",
      "Epoch: 17, c: 1, time: 548\n",
      "average  2880.92, test 3145.15, train 2616.70\n",
      "\n",
      "(36, 100)  \t 14.86293 \t  7.12117\n",
      "(100,)     \t  0.98709 \t  2.01354\n",
      "(100, 4)   \t  8.15061 \t  2.59576\n",
      "(4,)       \t  0.17014 \t  0.52834\n",
      "Updates 94880, Loss = 14.5973\n",
      "Epoch: 18, c: 1, time: 530\n",
      "average  3051.44, test 3151.43, train 2951.44\n",
      "\n",
      "(36, 100)  \t 15.39204 \t  6.09640\n",
      "(100,)     \t  1.05078 \t  1.73360\n",
      "(100, 4)   \t  8.50048 \t  1.66569\n",
      "(4,)       \t  0.18232 \t  0.37263\n",
      "Updates 94880, Loss = 12.2335\n",
      "Epoch: 19, c: 1, time: 578\n",
      "average  3057.57, test 3189.22, train 2925.92\n",
      "\n",
      "(36, 100)  \t 15.92208 \t  3.29806\n",
      "(100,)     \t  1.11517 \t  0.81494\n",
      "(100, 4)   \t  8.85048 \t  1.23427\n",
      "(4,)       \t  0.18998 \t  0.23088\n",
      "Updates 94880, Loss = 9.8419\n",
      "Epoch: 20, c: 1, time: 459\n",
      "average  2969.41, test 3032.29, train 2906.52\n",
      "\n",
      "(36, 100)  \t 16.39869 \t  3.40470\n",
      "(100,)     \t  1.17467 \t  0.96125\n",
      "(100, 4)   \t  9.10363 \t  0.91281\n",
      "(4,)       \t  0.19967 \t  0.17095\n",
      "Updates 94880, Loss = 9.1057\n",
      "Epoch: 21, c: 1, time: 562\n",
      "average  3037.99, test 3087.10, train 2988.88\n",
      "\n",
      "(36, 100)  \t 16.87707 \t  3.87589\n",
      "(100,)     \t  1.23966 \t  0.93499\n",
      "(100, 4)   \t  9.37926 \t  0.55692\n",
      "(4,)       \t  0.20242 \t  0.05924\n",
      "Updates 94875, Loss = 7.4767\n",
      "Epoch: 22, c: 1, time: 552\n",
      "average  3133.58, test 3239.54, train 3027.63\n",
      "\n",
      "(36, 100)  \t 17.36034 \t  5.13375\n",
      "(100,)     \t  1.30234 \t  1.50001\n",
      "(100, 4)   \t  9.63274 \t  1.92252\n",
      "(4,)       \t  0.19632 \t  0.37237\n",
      "Updates 94880, Loss = 6.5505\n",
      "Epoch: 23, c: 1, time: 492\n",
      "average  3134.96, test 3179.59, train 3090.33\n",
      "\n",
      "(36, 100)  \t 17.81533 \t  7.78530\n",
      "(100,)     \t  1.36455 \t  2.28184\n",
      "(100, 4)   \t  9.82098 \t  2.17762\n",
      "(4,)       \t  0.19035 \t  0.44815\n",
      "Updates 94880, Loss = 5.9053\n",
      "Epoch: 24, c: 1, time: 562\n",
      "average  3183.38, test 3237.22, train 3129.55\n",
      "\n",
      "(36, 100)  \t 18.24698 \t  2.66106\n",
      "(100,)     \t  1.41357 \t  0.61359\n",
      "(100, 4)   \t  9.98168 \t  1.02564\n",
      "(4,)       \t  0.18438 \t  0.16405\n",
      "Updates 94875, Loss = 5.6738\n",
      "Epoch: 25, c: 1, time: 503\n",
      "average  3028.45, test 3107.09, train 2949.81\n",
      "\n",
      "(36, 100)  \t 18.72988 \t  5.95025\n",
      "(100,)     \t  1.46718 \t  1.77514\n",
      "(100, 4)   \t 10.16192 \t  1.00527\n",
      "(4,)       \t  0.17922 \t  0.19726\n",
      "Updates 94875, Loss = 5.8327\n",
      "Epoch: 26, c: 1, time: 514\n",
      "average  3224.48, test 3171.15, train 3277.82\n",
      "\n",
      "(36, 100)  \t 19.11547 \t  4.31681\n",
      "(100,)     \t  1.51760 \t  1.31323\n",
      "(100, 4)   \t 10.31862 \t  1.67153\n",
      "(4,)       \t  0.17053 \t  0.30669\n",
      "Updates 94880, Loss = 5.4334\n",
      "Epoch: 27, c: 1, time: 558\n",
      "average  2966.57, test 3038.91, train 2894.23\n",
      "\n",
      "(36, 100)  \t 19.60750 \t  1.92382\n",
      "(100,)     \t  1.57263 \t  0.46578\n",
      "(100, 4)   \t 10.51812 \t  0.56283\n",
      "(4,)       \t  0.16743 \t  0.09142\n",
      "Updates 94875, Loss = 6.4019\n",
      "Epoch: 28, c: 1, time: 447\n",
      "average  3168.07, test 3164.60, train 3171.54\n",
      "\n",
      "(36, 100)  \t 20.04600 \t  5.63240\n",
      "(100,)     \t  1.62480 \t  1.70838\n",
      "(100, 4)   \t 10.69935 \t  2.09231\n",
      "(4,)       \t  0.16088 \t  0.40462\n",
      "Updates 94875, Loss = 6.3681\n",
      "Epoch: 29, c: 1, time: 438\n",
      "average  3186.40, test 3228.19, train 3144.61\n",
      "\n",
      "(36, 100)  \t 20.53959 \t  1.61312\n",
      "(100,)     \t  1.69091 \t  0.41674\n",
      "(100, 4)   \t 10.93811 \t  0.58704\n",
      "(4,)       \t  0.14616 \t  0.08283\n",
      "Updates 94880, Loss = 5.9545\n",
      "Epoch: 30, c: 1, time: 441\n",
      "average  2951.35, test 2917.10, train 2985.59\n",
      "\n",
      "(36, 100)  \t 20.97787 \t  4.25748\n",
      "(100,)     \t  1.75080 \t  1.02308\n",
      "(100, 4)   \t 11.16526 \t  1.48954\n",
      "(4,)       \t  0.13535 \t  0.18893\n",
      "Updates 94875, Loss = 6.8614\n",
      "Epoch: 31, c: 1, time: 441\n",
      "average  3179.10, test 3176.18, train 3182.02\n",
      "\n",
      "(36, 100)  \t 21.45731 \t  2.70789\n",
      "(100,)     \t  1.81307 \t  0.74934\n",
      "(100, 4)   \t 11.41327 \t  0.37005\n",
      "(4,)       \t  0.12114 \t  0.05165\n",
      "Updates 94875, Loss = 6.3859\n",
      "Epoch: 32, c: 1, time: 439\n",
      "average  2997.66, test 2975.81, train 3019.51\n",
      "\n",
      "(36, 100)  \t 21.96277 \t  6.01573\n",
      "(100,)     \t  1.88016 \t  1.59952\n",
      "(100, 4)   \t 11.67007 \t  1.86150\n",
      "(4,)       \t  0.10867 \t  0.26692\n",
      "Updates 94880, Loss = 6.8088\n",
      "Epoch: 33, c: 1, time: 447\n",
      "average  3203.31, test 3304.78, train 3101.83\n",
      "\n",
      "(36, 100)  \t 22.42529 \t  2.76788\n",
      "(100,)     \t  1.94573 \t  0.64834\n",
      "(100, 4)   \t 11.95119 \t  0.92220\n",
      "(4,)       \t  0.09173 \t  0.13521\n",
      "Updates 94880, Loss = 6.7295\n",
      "Epoch: 34, c: 1, time: 440\n",
      "average  2949.83, test 2901.60, train 2998.07\n",
      "\n",
      "(36, 100)  \t 22.94373 \t  2.54680\n",
      "(100,)     \t  2.02166 \t  0.54657\n",
      "(100, 4)   \t 12.27517 \t  0.78513\n",
      "(4,)       \t  0.07146 \t  0.11433\n",
      "Updates 94880, Loss = 6.9580\n",
      "Epoch: 35, c: 1, time: 445\n",
      "average  3237.30, test 3234.54, train 3240.06\n",
      "\n",
      "(36, 100)  \t 23.40263 \t  3.46853\n",
      "(100,)     \t  2.09722 \t  0.90258\n",
      "(100, 4)   \t 12.59005 \t  1.20267\n",
      "(4,)       \t  0.05290 \t  0.18385\n",
      "Updates 94880, Loss = 7.0841\n",
      "Epoch: 36, c: 1, time: 439\n",
      "average  3115.38, test 3048.52, train 3182.25\n",
      "\n",
      "(36, 100)  \t 23.87122 \t  6.86025\n",
      "(100,)     \t  2.19227 \t  2.10158\n",
      "(100, 4)   \t 12.89161 \t  1.85255\n",
      "(4,)       \t  0.03959 \t  0.37962\n",
      "Updates 94880, Loss = 6.5408\n",
      "Epoch: 37, c: 1, time: 443\n",
      "average  3176.43, test 3122.01, train 3230.84\n",
      "\n",
      "(36, 100)  \t 24.37261 \t  8.66405\n",
      "(100,)     \t  2.27322 \t  2.52703\n",
      "(100, 4)   \t 13.25067 \t  3.16626\n",
      "(4,)       \t  0.04200 \t  0.56426\n",
      "Updates 94880, Loss = 7.1779\n",
      "Epoch: 38, c: 1, time: 439\n",
      "average  3232.96, test 3184.03, train 3281.89\n",
      "\n",
      "(36, 100)  \t 24.87420 \t  8.25310\n",
      "(100,)     \t  2.36026 \t  2.43310\n",
      "(100, 4)   \t 13.62173 \t  1.74147\n",
      "(4,)       \t  0.06140 \t  0.31906\n",
      "Updates 94880, Loss = 6.4813\n",
      "Epoch: 39, c: 1, time: 441\n",
      "average  3005.29, test 2905.14, train 3105.44\n",
      "\n",
      "(36, 100)  \t 25.33918 \t  9.20049\n",
      "(100,)     \t  2.43593 \t  2.66901\n",
      "(100, 4)   \t 13.98765 \t  2.16691\n",
      "(4,)       \t  0.08437 \t  0.39870\n",
      "Updates 94880, Loss = 7.1459\n",
      "Epoch: 40, c: 1, time: 446\n",
      "average  3117.07, test 2983.30, train 3250.84\n",
      "\n",
      "(36, 100)  \t 25.84369 \t  8.11822\n",
      "(100,)     \t  2.52900 \t  2.38232\n",
      "(100, 4)   \t 14.36384 \t  2.09034\n",
      "(4,)       \t  0.11682 \t  0.38032\n",
      "Updates 94880, Loss = 6.9232\n",
      "Epoch: 41, c: 1, time: 441\n",
      "average  2991.98, test 2866.22, train 3117.73\n",
      "\n",
      "(36, 100)  \t 26.33193 \t 14.94252\n",
      "(100,)     \t  2.60497 \t  4.14776\n",
      "(100, 4)   \t 14.76253 \t  3.94829\n",
      "(4,)       \t  0.14944 \t  0.71519\n",
      "Updates 94880, Loss = 7.5420\n",
      "Epoch: 42, c: 1, time: 447\n",
      "average  3225.31, test 3122.84, train 3327.79\n",
      "\n",
      "(36, 100)  \t 26.84703 \t  2.19450\n",
      "(100,)     \t  2.69338 \t  0.52487\n",
      "(100, 4)   \t 15.20697 \t  0.45562\n",
      "(4,)       \t  0.18948 \t  0.03836\n",
      "Updates 94880, Loss = 7.4217\n",
      "Epoch: 43, c: 1, time: 444\n",
      "average  3150.57, test 3038.01, train 3263.13\n",
      "\n",
      "(36, 100)  \t 27.34653 \t  2.47331\n",
      "(100,)     \t  2.78406 \t  0.58696\n",
      "(100, 4)   \t 15.63839 \t  0.53491\n",
      "(4,)       \t  0.22478 \t  0.03191\n",
      "Updates 94880, Loss = 8.0434\n",
      "Epoch: 44, c: 1, time: 445\n",
      "average  3175.27, test 2982.21, train 3368.33\n",
      "\n",
      "(36, 100)  \t 27.83271 \t  2.77061\n",
      "(100,)     \t  2.86492 \t  0.59431\n",
      "(100, 4)   \t 16.09885 \t  0.57298\n",
      "(4,)       \t  0.26211 \t  0.06614\n",
      "Updates 94880, Loss = 8.4581\n",
      "Epoch: 45, c: 1, time: 440\n",
      "average  3072.24, test 2881.63, train 3262.85\n",
      "\n",
      "(36, 100)  \t 28.25162 \t  4.94941\n",
      "(100,)     \t  2.94831 \t  1.43369\n",
      "(100, 4)   \t 16.45667 \t  0.79995\n",
      "(4,)       \t  0.29116 \t  0.12120\n",
      "Updates 94880, Loss = 8.3621\n",
      "Epoch: 46, c: 1, time: 442\n",
      "average  3221.01, test 3051.57, train 3390.45\n",
      "\n",
      "(36, 100)  \t 28.65732 \t  4.70280\n",
      "(100,)     \t  3.00954 \t  1.05302\n",
      "(100, 4)   \t 16.79627 \t  0.71413\n",
      "(4,)       \t  0.31903 \t  0.04168\n",
      "Updates 94880, Loss = 8.3639\n",
      "Epoch: 47, c: 1, time: 439\n",
      "average  3279.42, test 3044.77, train 3514.08\n",
      "\n",
      "(36, 100)  \t 29.14645 \t  2.30577\n",
      "(100,)     \t  3.08835 \t  0.52652\n",
      "(100, 4)   \t 17.22998 \t  0.72769\n",
      "(4,)       \t  0.35989 \t  0.11310\n",
      "Updates 94880, Loss = 8.2021\n",
      "Epoch: 48, c: 1, time: 436\n",
      "average  3318.39, test 3144.02, train 3492.76\n",
      "\n",
      "(36, 100)  \t 29.60373 \t  2.97683\n",
      "(100,)     \t  3.15894 \t  0.82329\n",
      "(100, 4)   \t 17.63481 \t  0.74213\n",
      "(4,)       \t  0.39447 \t  0.11684\n",
      "Updates 94880, Loss = 8.2071\n",
      "Epoch: 49, c: 1, time: 434\n",
      "average  3296.36, test 3058.21, train 3534.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = policy_iteration(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('list_weights_hid100.pkl', 'wb') as f:\n",
    "    cPickle.dump(W, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  3262.12, test 3152.61, train 3371.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3371.626953125, 3152.614990234375]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test(np.array(W[30:]).mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('mean_weights_hid100.pkl', 'wb') as f:\n",
    "    cPickle.dump(np.array(W[30:]).mean(axis = 0), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
